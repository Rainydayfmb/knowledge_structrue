<!-- TOC -->

- [1. 概述](#1-概述)
    - [1.1. 为什么使用消息队列](#11-为什么使用消息队列)
        - [1.1.1. 解耦](#111-解耦)
        - [1.1.2. 异步](#112-异步)
        - [1.1.3. 削峰](#113-削峰)
    - [1.2. 消息队列有什么优缺点](#12-消息队列有什么优缺点)
        - [1.2.1. 优点](#121-优点)
        - [1.2.2. 缺点](#122-缺点)
    - [1.3. Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？](#13-kafkaactivemqrabbitmqrocketmq-有什么优缺点)
    - [1.4. MQ消息最终一致性解决方案](#14-mq消息最终一致性解决方案)
        - [1.4.1. 问题背景](#141-问题背景)
        - [1.4.2. 普通消息处理流程](#142-普通消息处理流程)
        - [1.4.3. 普通消息处理存在的一致性问题](#143-普通消息处理存在的一致性问题)
        - [1.4.4. 一个错误的想法](#144-一个错误的想法)
        - [1.4.5. 事务消息](#145-事务消息)
        - [1.4.6. 事务消息处理的流程](#146-事务消息处理的流程)
        - [1.4.7. 事务消息异常情况分析](#147-事务消息异常情况分析)
        - [1.4.8. 支持事务消息的MQ](#148-支持事务消息的mq)
        - [1.4.9. 基于本地消息的最终一致性](#149-基于本地消息的最终一致性)
        - [1.4.10. 独立消息服务的最终一致性](#1410-独立消息服务的最终一致性)

<!-- /TOC -->
# 1. 概述
## 1.1. 为什么使用消息队列
消息队列常见的使用场景有很多，但是比较核心的有 3 个：解耦、异步、削峰。
### 1.1.1. 解耦
A系统需要发送消息到BCD等系统，如果采用接口调用的方式，在增加或删除一个系统交互的时候都需要更改代码和系统一场的考虑。
![avator](https://raw.githubusercontent.com/doocs/advanced-java/master/images/mq-1.png)

如果使用mq,就不用考虑这种问题。
![avator](https://raw.githubusercontent.com/doocs/advanced-java/master/images/mq-2.png)

总结：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。

### 1.1.2. 异步
再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。

![avator](https://raw.githubusercontent.com/doocs/advanced-java/master/images/mq-3.png)

**一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。**

如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！
![avator](https://raw.githubusercontent.com/doocs/advanced-java/master/images/mq-4.png)

### 1.1.3. 削峰
每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。

**一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。**

但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。

![avator](https://raw.githubusercontent.com/doocs/advanced-java/master/images/mq-5.png)

如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。

![avator](https://raw.githubusercontent.com/doocs/advanced-java/master/images/mq-6.png)

这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。

## 1.2. 消息队列有什么优缺点

### 1.2.1. 优点
在特殊场景下有其对应的好处，解耦、异步、削峰。

### 1.2.2. 缺点
缺点有以下几个：
- 系统可用性降低
    系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，ABCD 四个系统还好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整？MQ 一挂，整套系统崩溃，你不就完了？如何保证消息队列的高可用，可以点击这里查看。

- 系统复杂度提高
    硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。

- 一致性问题
    A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。

## 1.3. Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？
特性 | ActiveMQ | RabbitMQ | RocketMQ | Kafka
:-: | :-: | :-: | :-: | :-: 
单机吞吐量	  |万级，比 RocketMQ、Kafka 低一个数量级	 |同 ActiveMQ | 10 万级，支撑高吞吐 | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景
topic 数量对吞吐量的影响	  |	 | |topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源
时效性	  |ms 级	 |微秒级，这是 RabbitMQ 的一大特点，延迟最低 | ms 级 | 延迟在 ms 级以内
可用性	  |高，基于主从架构实现高可用	 |同 ActiveMQ | 非常高，分布式架构 | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用
消息可靠性	  |有较低的概率丢失数据	|基本不丢 | 经过参数优化配置，可以做到 0 丢失 | 同 RocketMQ
功能支持	  |MQ 领域的功能极其完备	 |基于 erlang 开发，并发能力很强，性能极好，延时很低 | MQ 功能较为完善，还是分布式的，扩展性好 | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用

综上，各种对比之后，有如下建议：

一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；

后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；

不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。

所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。

如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。


## 1.4. MQ消息最终一致性解决方案
[参考](https://www.jianshu.com/p/eb571e4065ec)

### 1.4.1. 问题背景
多服务之间的远程调用会带来分布式事务的问题，多个服务之间使用自己单独维护的数据库,彼此之间不在同一个事务中，假如A提交成功，B执行失败，A的事务已经提交，无法回滚，最终会导致两边的数据不一致。

### 1.4.2. 普通消息处理流程
![aviator](https://upload-images.jianshu.io/upload_images/1684370-5a225e6eb5c076ca.png?imageMogr2/auto-orient/strip|imageView2/2/w/904)
1. 消息生成者发送消息；
2. MQ收到消息，将消息进行持久化，在存储中新增一条记录
3. 返回ACK给生产者；
4. MQ push消息给对应的消费者，然后等待消费者返回ACK;
5. 如果消息消费者在指定的消息内成功返回ACK,那么MQ认为消息消费成功，在存储中删除消息，即执行第6步；如果MQ在指定的时间内没有收到ACK,则认为消息消费失败，会尝试重新push消息，重复执行4，5，6步骤
6. MQ删除消息

### 1.4.3. 普通消息处理存在的一致性问题
我们以订单创建为例，订单系统先创建订单(本地事务)，再发送消息给下游处理；如果订单创建成功，然而消息没有发送出去，那么下游所有系统都无法感知到这个事件，会出现脏数据；
```java
public void processOrder() {
    // 订单处理(业务操作) 
    orderService.process();
    // 发送订单处理成功消息(发送消息) 
    sendBizMsg ();
}
```

如果先发送订单消息，再创建订单；那么就有可能消息发送成功，但是在订单创建的时候却失败了，此时下游系统却认为这个订单已经创建，也会出现脏数据。
```java
public void processOrder() {
   // 发送订单处理成功消息(发送消息) 
    sendBizMsg ();
    // 订单处理(业务操作) 
    orderService.process();
}
```

### 1.4.4. 一个错误的想法
此时可能有同学会想，我们可否将消息发送和业务处理放在同一个本地事务中来进行处理，如果业务消息发送失败，那么本地事务就回滚，这样是不是就能解决消息发送的一致性问题呢?
```java
@Transactionnal
public void processOrder() {
    try{
        // 订单处理(业务操作) 
        orderService.process(); 
        // 发送订单处理成功消息(发送消息) 
        sendBizMsg ();
    }catch(Exception e){
         事务回滚;   
    }
}
```
从上面的情况分析，我们可以看到，使用普通的处理方式，无论如何，都无法保证业务处理与消息发送两边的一致性，其根本的原因就在于：远程调用，结果最终可能为成功、
失败、超时；而对于超时的情况，处理方最终的结果可能是成功，也可能是失败，调用方是无法知晓的。 笔者就曾经在项目中出现类似的情况，调用方先在本地写数据，
然后发起RPC服务调用，但是处理方由于DB数据量比较大，导致处理超时，调用方在出现超时异常后，直接回滚本地事务，从而导致调用方这边没数据，
而处理方那边数据却已经写入了，最终导致两边业务数据的不一致。为了保证两边数据的一致性，我们只能从其他地方寻找新的突破口。

### 1.4.5. 事务消息
由于传统的处理方式无法解决消息生成者本地事务处理成功与消息发送成功两者的一致性问题，因此事务消息就诞生了，它实现了消息生成者本地事务与消息发送的原子性，
保证了消息生成者本地事务处理成功与消息发送成功的最终一致性问题。

### 1.4.6. 事务消息处理的流程
![avaiator](https://upload-images.jianshu.io/upload_images/1684370-f84835acfdd0507e.png?imageMogr2/auto-orient/strip|imageView2/2/w/943)
1. 事务消息与普通消息的区别在于消息生产的环节，生产者首先预发送一条消息到MQ(这也被称为half消息)
2. MQ接收到消息后，先执行持久化，则存储中会新增一条状态为待发送的消息
3. 然后返回ACK给消息生产者，此时MQ不会触发消息推送事件；
4. 生产者预发送消息后，执行本地事务；
5. 执行本地事务，执行完后，发送执行结果给MQ；
6. MQ会根据结果删除或者更新状态为可发送；
7. 如果消息状态更新为可发送，则MQ会push消息给消费者，后面消息的消费和普通的消息是一样的；
**注意点**：由于MQ通常都会保证消息能够投递成功，因此，如果业务没有及时返回ACK结果，那么就有可能造成MQ的重复消息投递问题。因此，对于消息最终一致性的方案，消息的消费者必须要对消息的消费支持幂等，不能造成同一条消息的重复消费的情况。

### 1.4.7. 事务消息异常情况分析
异常情况 | 一致性 | 处理异常方法
:-: | :-: | :-:
消息未存储，业务操作未执行 | 一致 | 无
存储待发送消息成功，但是ACK失败，导致业务未执行(可能是MQ处理超时，网络抖动等原因) | 不一致 | MQ确认业务操作结果，处理消息(删除消息)
存储待发送消息成功，ACK成功，业务执行(可能成功也可能失败)，但是MQ没有收到生产者业务处理的最终结果 | 不一致 | MQ确认业务操作结果，处理消息(根据就业务处理结果，更新消息状态，如果业务执行成功，则投递消息，失败则删除消息)
业务处理成功，并且发送结果给MQ，但是MQ更新消息失败，导致消息状态依旧为待发送  |  不一致  | 同上

### 1.4.8. 支持事务消息的MQ
现在目前较为主流的MQ，比如ActiveMQ、RabbitMQ、Kafka、RocketMQ等，只有RocketMQ支持事务消息。据笔者了解，早年阿里对MQ增加事务消息也是因为支付宝那边因为业务上的需求而产生的。
因此，如果我们希望强依赖一个MQ的事务消息来做到消息最终一致性的话，在目前的情况下，技术选型上只能去选择RocketMQ来解决。上面我们也分析了事务消息所存在的异常情况，即MQ存储了待发送的消息，但是MQ无法感知到上游处理的最终结果。
对于RocketMQ而言，它的解决方案非常的简单，就是其内部实现会有一个定时任务，去轮训状态为待发送的消息，然后给producer发送check请求，而producer必须实现一个check监听器，监听器的内容通常就是去检查与之对应的本地事务是否成功(一般就是查询DB)，如果成功了，则MQ会将消息设置为可发送，否则就删除消息。

### 1.4.9. 基于本地消息的最终一致性
![avaitor](https://upload-images.jianshu.io/upload_images/1684370-c5a20749a59fc1a8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1049)
基于本地消息的最终一致性方案的最核心做法就是在执行业务操作的时候，记录一条消息数据到DB，并且消息数据的记录与业务数据的记录必须在同一个事务内完成，这是该方案的前提核心保障。在记录完成后消息数据后，后面我们就可以通过一个定时任务到DB中去轮训状态为待发送的消息，然后将消息投递给MQ。这个过程中可能存在消息投递失败的可能，此时就依靠重试机制来保证，直到成功收到MQ的ACK确认之后，再将消息状态更新或者消息清除；而后面消息的消费失败的话，则依赖MQ本身的重试来完成，其最后做到两边系统数据的最终一致性。基于本地消息服务的方案虽然可以做到消息的最终一致性，但是它有一个比较严重的弊端，每个业务系统在使用该方案时，都需要在对应的业务库创建一张消息表来存储消息。针对这个问题，我们可以将该功能单独提取出来，做成一个消息服务来统一处理，因而就衍生出了我们下面将要讨论的方案。


### 1.4.10. 独立消息服务的最终一致性
![avaitor](https://upload-images.jianshu.io/upload_images/1684370-d36234ba75d83a95.png?imageMogr2/auto-orient/strip|imageView2/2/w/1134)
独立消息服务最终一致性与本地消息服务最终一致性最大的差异就在于将消息的存储单独地做成了一个RPC的服务，这个过程其实就是模拟了事务消息的消息预发送过程，如果预发送消息失败，那么生产者业务就不会去执行，因此对于生产者的业务而言，它是强依赖于该消息服务的。不过好在独立消息服务支持水平扩容，因此只要部署多台，做成HA的集群模式，就能够保证其可靠性。在消息服务中，还有一个单独地定时任务，它会定期轮训长时间处于待发送状态的消息，通过一个check补偿机制来确认该消息对应的业务是否成功，如果对应的业务处理成功，则将消息修改为可发送，然后将其投递给MQ；如果业务处理失败，则将对应的消息更新或者删除即可。因此在使用该方案时，消息生产者必须同时实现一个check服务，来供消息服务做消息的确认。对于消息的消费，该方案与上面的处理是一样，都是通过MQ自身的重发机制来保证消息被消费。



