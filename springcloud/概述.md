<!-- TOC -->

- [1. 概述](#1-概述)
    - [1.1. 引出Eureka](#11-引出eureka)
        - [1.1.1. Eureka细节](#111-eureka细节)
    - [1.2. 引出RestTemplate和Ribbon](#12-引出resttemplate和ribbon)
        - [1.2.1. ribbon细节](#121-ribbon细节)
    - [1.3. 引入Hystrix](#13-引入hystrix)
        - [1.3.1. hystrix仪表盘](#131-hystrix仪表盘)
    - [1.4. 引出feign](#14-引出feign)
    - [1.5. 引出zuul](#15-引出zuul)
        - [1.5.1. zuul的疑问](#151-zuul的疑问)
    - [1.6. 引出SpringCloud Config](#16-引出springcloud-config)
    - [1.7. 引出SpringCloud bus](#17-引出springcloud-bus)
        - [1.7.1. 传统的消息系统](#171-传统的消息系统)
            - [1.7.1.1. activemq](#1711-activemq)
            - [1.7.1.2. kafka](#1712-kafka)
            - [1.7.1.3. RocketMQ](#1713-rocketmq)
            - [1.7.1.4. RabbitMQ](#1714-rabbitmq)
            - [1.7.1.5. Redis](#1715-redis)
        - [1.7.2. 什么时候使用cloud bus](#172-什么时候使用cloud-bus)

<!-- /TOC -->
# 1. 概述
[参考](https://www.zhihu.com/question/283286745/answer/763040709)
**为什么需要springcloud**
![avator](https://pic2.zhimg.com/80/v2-f21366fc84bf715742fd8cc5971c3f13_1440w.jpg)
拆分出多个模块以后，就会出现各种各样的问题，而SpringCloud提供了一整套的解决方案！

**springcloud的基础功能**
- 服务治理：Spring Cloud Eureka
- 客户端负载均衡： Spring Cloud Ribbon
- 服务容错保护：Spring Cloud Hystrix
- 声明式服务调用：Spring Cloud Feign
- API网关服务：Spring Cloud Zuul
- 分布式配置中心： Spring Cloud Config

**springcloud的高级功能**
- 消息总线：Spring Cloud Bus
- 消息驱动的为服务：Spring Cloud Stream
- 分布式服务跟踪：Spring Cloud Sleuth

## 1.1. 引出Eureka 
子系统与子系统之间不在一个环境下，那就需要远程调用，类似于httpclient,webservice等等这类技术来实现。

远程调用需要知道ip和地址，当系统比较复杂，维护起来成本很高。

springcloud中我们的服务治理框架用一般使用的就是Eureka,eureka是这么解决这种问题的：
创建一个E服务，将A,B,C,D四个服务的信息都注册到E上面，E服务维护这些已经注册捡来的信息
![avator](https://pic4.zhimg.com/80/v2-ddb398e19d3b3eb0cd035b72fcd94d72_1440w.jpg)

A、B、C、D四个服务都可以拿到Eureka(服务E)那份注册清单。A、B、C、D四个服务互相调用不再通过具体的IP地址，而是通过服务名来调用！
- 拿到注册清单--->注册清单上有服务名--->自然就能够拿到服务具体的位置了(IP)。
- 其实简单来说就是：代码中通过服务名找到对应的IP地址(IP地址会变，但服务名一般不会变)

具体的存储形式如下图所示：
![avator](https://pic4.zhimg.com/80/v2-5913ec6dc3604a877fca57cf77e35247_1440w.jpg)

### 1.1.1. Eureka细节
Eureka专门用于给其他服务注册的称为Eureka Server(服务注册中心)，其余注册到Eureka Server的服务称为Eureka Client。
![avator](https://pic2.zhimg.com/80/v2-98a71ef8e7577de3bc22341a9532812e_1440w.jpg)

**下面是Eureka的治理机制**
- 服务提供者

    1.服务注册：启动的时候会通过发送REST请求的方式将自己注册到Eureka Server上，同时带上了自身服务的一些元数据信息。

    2.服务续约：在注册完服务之后，服务提供者会维护一个心跳用来持续告诉Eureka Server。

    3.服务下线：当服务实例进行正常的关闭操作时，它会触发一个服务下线的REST请求给Eureka Server, 告诉服务注册中心：“我要下线了 ”。

- 服务消费者

    1.获取服务：当我们启动服务消费者的时候，它会发送一个REST请求给服务注册中心，来获取上面注册的服务清单。

    2.服务调用：服务消费者在获取服务清单后，通过服务名可以获得具体提供服务的实例名和该实例的元数据信息。在进行服务调用的时候，优先访问同处一个Zone中的服务提供方。

- Eureka Server(服务注册中心)：

    1.失效剔除：默认每隔一段时间（默认为60秒） 将当前清单中超时（默认为90秒）没有续约的服务剔除出去。

    2.自我保护：。EurekaServer 在运行期间，会统计心跳失败的比例在15分钟之内是否低于85%(通常由于网络不稳定导致)。 Eureka Server会将当前的实例注册信息保护起来， 让这些实例不会过期，尽可能保护这些注册信息。

最后我们就有了这张图
![avator](https://pic3.zhimg.com/80/v2-22ac91d35e2f2da97c6e8fd70c359f84_1440w.jpg)


## 1.2. 引出RestTemplate和Ribbon
可以使用Spring封装好的RestTemplate工具类，使用起来很简单：
```
// 传统的方式，直接显示写死IP是不好的！
    //private static final String REST_URL_PREFIX = "http://localhost:8001";
	
	// 服务实例名
    private static final String REST_URL_PREFIX = "http://MICROSERVICECLOUD-DEPT";

    /**
     * 使用 使用restTemplate访问restful接口非常的简单粗暴无脑。 (url, requestMap,
     * ResponseBean.class)这三个参数分别代表 REST请求地址、请求参数、HTTP响应转换被转换成的对象类型。
     */
    @Autowired
    private RestTemplate restTemplate;

    @RequestMapping(value = "/consumer/dept/add")
    public boolean add(Dept dept) {
        return restTemplate.postForObject(REST_URL_PREFIX + "/dept/add", dept, Boolean.class);
    }
```

![avator](https://pic2.zhimg.com/80/v2-63e41a04b3e7608b11c7ba7d63eb803e_1440w.jpg)
业务场景，负载均衡，如何合理的分配用户的请求，我们常用的方法就是使用nginx

负载均衡又分为两种类型
- 客户端负载均衡

    - 服务清单的示例在客户端，客户端进行负载均衡的算法分配
    - 客户端可以从eureka server中得到一份服务清单，在发送请求时通过负载均衡的算法，在多个服务器之间选择一个进行访问
    
- 服务端负载均衡

    - 服务示例的清单在服务端，服务器进行负载均衡算法分配

整个流程如下图所示：
![avator](https://pic4.zhimg.com/80/v2-3cebcf81da382b55f4e9e740b48c727e_1440w.jpg)

### 1.2.1. ribbon细节
ribbon是支持负载均衡，默认的负载均衡策略是轮询


## 1.3. 引入Hystrix
有了eureka和ribbion我们的服务可以提供服务发现和ribbion负载均衡

但是，如果我们在调用多个远程服务时，某个服务出现延迟，会怎么样？？
![avator](https://pic4.zhimg.com/80/v2-ee1afefe18f265276a8524881b87b372_1440w.jpg)

在高并发的情况下，由于单个服务的延迟，可能导致所有的请求都处于延迟状态，甚至在几秒钟就使服务处于负载饱和的状态，资源耗尽，直到不可用，最终导致这个分布式系统都不可用，这就是“雪崩”。

![avator](https://pic1.zhimg.com/80/v2-489c520f885f1d2152666a106ecd1d0b_1440w.jpg)

针对上面的问题，spring cloud htstrix实现了熔断器、线程隔离等一系列服务的保护功能

- Fallback(失败快速返回)：当某个服务单元发生故障（类似用电器发生短路）之后，通过断路器的故障监控（类似熔断保险丝）， 向调用方返回一个错误响应， 而不是长时间的等待。这样就不会使得线程因调用故障服务被长时间占用不释放，避免了故障在分布式系统中的蔓延。

- 资源/依赖隔离(线程池隔离)：它会为每一个依赖服务创建一个独立的线程池，这样就算某个依赖服务出现延迟过高的情况，也只是对该依赖服务的调用产生影响， 而不会拖慢其他的依赖服务。

Hystrix提供几个熔断关键参数：滑动窗口大小（20）、 熔断器开关间隔（5s）、错误率（50%）

- 每当20个请求中，有50%失败时，熔断器就会打开，此时再调用此服务，将会直接返回失败，不再调远程服务。
- 直到5s钟之后，重新检测该触发条件，判断是否把熔断器关闭，或者继续打开。

### 1.3.1. hystrix仪表盘

现在整个系统是这个样子的
![avator](https://pic1.zhimg.com/80/v2-e729d17396dcf89ea55d47ff27759268_1440w.jpg)

除了可以开启单个实例的监控页面之外，还有一个监控端点 /turbine.stream是对集群使用的。 从端点的命名中，可以引入Turbine, 通过它来汇集监控信息，并将聚合后的信息提供给 HystrixDashboard 来集中展示和监控。

![avator](https://pic1.zhimg.com/80/v2-7540217e59fbb2e2ffb2e86d75286ca2_1440w.jpg)

## 1.4. 引出feign
上面已经介绍了Ribbon和Hystrix了，可以发现的是：他俩作为基础工具类框架广泛地应用在各个微服务的实现中。我们会发现对这两个框架的使用几乎是同时出现的。为了简化我们的开发，Spring Cloud Feign出现了！它基于 Netflix Feign 实现，整合了 Spring Cloud Ribbon 与 Spring Cloud Hystrix, 除了整合这两者的强大功能之外，它还提 供了声明式的服务调用(不再通过RestTemplate)。

Feign是一种声明式、模板化的HTTP客户端。在Spring Cloud中使用Feign, 我们可以做到使用HTTP请求远程服务时能与调用本地方法一样的编码体验，开发者完全感知不到这是远程方法，更感知不到这是个HTTP请求。


## 1.5. 引出zuul
基于上面的学习，我们现在的架构很可能会设计成这样：
![avator](https://pic1.zhimg.com/80/v2-774958b647a594ffc310580c26f7ef33_1440w.jpg)

这样的架构会有两个问题：
- 这样的架构会有两个比较麻烦的问题：路由规则与服务实例的维护间题：外层的负载均衡(nginx)需要维护所有的服务实例清单(图上的OpenService)
- 签名校验、 登录校验冗余问题：为了保证对外服务的安全性， 我们在服务端实现的微服务接口，往往都会有一定的权限校验机制，但我们的服务是独立的，我们不得不在这些应用中都实现这样一套校验逻辑，这就会造成校验逻辑的冗余。

![avator](https://pic1.zhimg.com/80/v2-6c9474c1b5c851ff20d2d50b209b3cdd_1440w.jpg)

每个服务都有自己的IP地址，Nginx想要正确请求转发到服务上，就必须维护着每个服务实例的地址！

更是灾难的是：这些服务实例的IP地址还有可能会变，服务之间的划分也很可能会变。

购物车和订单模块都需要用户登录了才可以正常访问，基于现在的架构，只能在购物车和订单模块都编写校验逻辑，这无疑是冗余的代码。


为了解决上面这些常见的架构问题，API网关的概念应运而生。在SpringCloud中了提供了基于Netfl ix Zuul实现的API网关组件Spring Cloud Zuul。

Spring Cloud Zuul是这样解决上述两个问题的：

- SpringCloud Zuul通过与SpringCloud Eureka进行整合，将自身注册为Eureka服务治理下的应用，同时从Eureka中获得了所有其他微服务的实例信息。外层调用都必须通过API网关，使得将维护服务实例的工作交给了服务治理框架自动完成。

- 在API网关服务上进行统一调用来对微服务接口做前置过滤，以实现对微服务接口的拦截和校验。


Zuul天生就拥有线程隔离和断路器的自我保护功能，以及对服务调用的客户端负载均衡功能。也就是说：Zuul也是支持Hystrix和Ribbon。

关于Zuul还有很多知识点(由于篇幅问题，这里我就不细说了)：
- 路由匹配(动态路由)
- 过滤器实现(动态过滤器)
- 默认会过滤掉Cookie与敏感的HTTP头信息(额外配置)

### 1.5.1. zuul的疑问
Zuul支持Ribbon和Hystrix，也能够实现客户端的负载均衡。我们的Feign不也是实现客户端的负载均衡和Hystrix的吗？既然Zuul已经能够实现了，那我们的Feign还有必要吗？

![avator](https://pic4.zhimg.com/80/v2-4979061b2ecb7230d0e4e0d91bbd0e81_1440w.jpg)

或者可以这样理解：
- zuul是对外暴露的唯一接口相当于路由的是controller的请求，而Ribbonhe和Fegin路由了service的请求
- zuul做最外层请求的负载均衡 ，而Ribbon和Fegin做的是系统内部各个微服务的service的调用的负载均衡


## 1.6. 引出SpringCloud Config

随着业务的扩展，我们的服务会越来越多，越来越多。每个服务都有自己的配置文件。

既然是配置文件，给我们配置的东西，那难免会有些改动的。

比如我们的Demo中，每个服务都写上相同的配置文件。万一我们有一天，配置文件中的密码需要更换了，那就得三个都要重新更改。

Spring Cloud Config项目是一个解决分布式系统的配置管理方案。它包含了Client和Server两个部分，server提供配置文件的存储、以接口的形式将配置文件的内容提供出去，client通过接口获取数据、并依据此数据初始化自己的应用。

- 简单来说，使用Spring Cloud Config就是将配置文件放到统一的位置管理(比如GitHub)，客户端通过接口去获取这些配置文件。
- 在GitHub上修改了某个配置文件，应用加载的就是修改后的配置文件。

![avator](https://pic4.zhimg.com/80/v2-fc31b93cdf89368a5791489e330a91ed_1440w.jpg)

## 1.7. 引出SpringCloud bus

### 1.7.1. 传统的消息系统  
#### 1.7.1.1. activemq
老牌的消息系统，出现的比较早，美中不足的是不能支持超大规模、超高并发的的互联网应用，activemq的并发承受能力在百万级别，大概500次/s

#### 1.7.1.2. kafka
新一代的消息系统，相对于activemq来说增加了分片的功能，类似于数据库的分库分表，一台broker仅负责一部分数据收发，从而使得它的伸缩性特别好，通过增加broker就可以不断增加处理能力。一般来说，kafka被用来处理日志流，作为计算的接入点。在电商的订单、库存等系统里面一般不用，主要顾虑是kafka的异步刷盘机制可能会导致数据丢失。当然，对于数据丢失这一点不同的工程师也有不同的看法，认为Kafka的Master-Slave的多写机制，完全能够避免数据丢失。

#### 1.7.1.3. RocketMQ
是阿里开源的一款消息系统，开发的初衷就是要支撑阿里庞大的电商系统。RocketMQ和Kafka有很多相似之处，由于RocketMQ开发中很大程度上参考了Kafka的实现。RocketMQ同样提供了优秀的分片机制，RocketMQ的分片比Kafka的分片有所增强，区分了绝对有序和非绝对有序两种选项。另外RocketMQ采用的是同步刷盘，一般认为不会造成数据丢失。

#### 1.7.1.4. RabbitMQ
类似于ActiveMQ也是一个相对小型的消息系统，他的优势在于灵活的路由机制，可以进行自由配置。

#### 1.7.1.5. Redis
 Redis的pub/sub功能，由于Redis是内存级的系统，所以速度和单机的并发能力是上述四个消息系统不能比拟的，但是也是由于内存存储的缘故，在消息的保障上就更弱一些。据说新浪博客系统选择了Redis的pub/sub作为消息系统，不能不说艺高人胆大。

### 1.7.2. 什么时候使用cloud bus
bus 就是消息总线，可以联通后台的多个服务器，为什么需要cloud bus 进行串联？后端服务器一般都是集群化的，在大促活动期间经常发生服务器的扩容、缩容、上下线等操作，后端服务器的ip会发生变化，需要维护ip；比如我们需要更新配置、同时失效所有服务器上的某个缓存等等；

一般我们会采用zk的方式统一管理所有服务器的ip地址，但是这种方案的解藕性，灵活性和实时性会比消息消息总线的方式差一些。

总体来说，就是我们需要把一个操作散发到所有后端相关的服务器的时候，就可以选择pring bus,使用了cloud bus之后，我们的服务架构会变成如下图所示：
![avator](https://img-blog.csdn.net/20171202221915378?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvQnVxdVRpYW55YQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

当前spring cloud bus提供了两个可用的接口:1./bus/env用于设置某一个配置项2./bus/refresh用于刷新所有绑定到刷新点的配置项。

这两个接口是使用spring boot actuator方式发布出来的（可以参见：深入SpringBoot:自定义Endpoint一文），接收到消息后会使用spring的stream框架（可以参考：张开涛的解Spring事件驱动模型一文）把消息传播到所有注册的相关服务器。

//todo
- kafka的异步刷盘机制
- spring的stream框架
- spring的事件驱动模型
- myql的数据库扩容原理



