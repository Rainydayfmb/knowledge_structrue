# Redis

## rehash
  [渐进式 rehash 策略](http://redisbook.com/preview/dict/incremental_rehashing.html):为了避免 rehash 对服务器性能造成影响， 服务器不是一次性将 ht[0] 里面的所有键值对全部 rehash 到 ht[1] ， 而是分多次、渐进式地将 ht[0] 里面的键值对慢慢地 rehash 到 ht[1] 。
### rehash 的详细步骤：
- 为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。
- 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。
- 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。
- 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。

### 触发扩容的条件
- 如果哈希表ht[0]中保存的key个数与哈希表大小的比例已经达到1:1，即保存的节点数已经大于哈希表大小，且redis服务当前允许执行rehash
- 或者保存的节点数与哈希表大小的比例超过了安全阈值（默认值为5）
则将哈希表大小扩容为原来的两倍
- [redis渐进式rehash机制](https://luoming1224.github.io/2018/11/12/[redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0]redis%E6%B8%90%E8%BF%9B%E5%BC%8Frehash%E6%9C%BA%E5%88%B6/)

## redis的java客户端jedis
[jedis实例是非线程安全的](https://www.jianshu.com/p/5e4a1f92c88f),常常通过JedisPool连接池去管理实例，在多线程情况下让每个线程有自己独立的jedis实例。Redis所有单个命令的执行都是原子性的，这与它的单线程机制有关；
jedi实例不是线程安全的原因：

## redis 哨兵模式
[参考](https://www.jianshu.com/p/06ab9daf921d)
主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑
### 哨兵模式概念
哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。
![avatar](https://upload-images.jianshu.io/upload_images/11320039-57a77ca2757d0924.png?imageMogr2/auto-orient/strip|imageView2/2/w/507)
- 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。
- 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。

然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。

用文字描述一下故障切换（failover）的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为**主观下线**。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为**客观下线**。这样对于客户端而言，一切都是透明的。

### Redis配置哨兵模式
![avatar](https://upload-images.jianshu.io/upload_images/11320039-3f40b17c0412116c.png?imageMogr2/auto-orient/strip|imageView2/2/w/747)

## Redis的过期和内存淘汰策略
### Redis过期策略
redis的过期策略是：定期删除+惰性删除
#### 定期删除
redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。除了定时遍历之外，它还会使用惰性策略来删除过期的 key，所谓惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期了就立即删除。定时删除是集中处理，惰性删除是零散处理。

redis里面默认每隔100ms就随机抽取一些设置了过期时间的key,检查其是否已经过期，如果过期就对其进行删除。
假设redis里放了10w个key,都设置了过期时间，每隔几百毫秒，就检查10w个key,那redis基本上就死了，cpu的负载会很高，消耗在检查过期的key上了。注意，这里可不是每隔100ms就遍历所有设置了过期时间的key，那样就是一场性能上的灾难。实际上redis是每隔100ms随机抽取一些key来检查和进行删除的。

#### 定期删除策略
Redis 默认会每秒进行十次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。
- 从过期字典种随机取20个key;
- 删除这20个key中已经过期的key;
- 如果过期的key比率超过1/4，那就重复步骤1；

同时，为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认的不过超过25ms。

设想一个大型的redis实例中所有的key在同一时间过期了，或出现怎样的结果？
毫无疑问，Redis会持续扫描过期字段(循环多次)，直到过期字典中过期的key变得稀疏，才会停止(循环次数明显下降)。这就会导致线上读写请求出现明显的卡顿现象。导致这种卡顿的另外一种原因是内存管理器需要频繁回收内存页，这也会产生一定的CPU消耗。
当客户端的请求到来的时候，服务端如果正好进入过期的扫描状态，客户端的请求将会至少等到至少25ms后才会进行处理，如果客户端将超时时间设置的比较短，比如10ms,那么就会出现大量的链接因为超时而关闭，业务端就会出现很多异常。而且这时你还无法从Redis的slowlog中看到满查询的记录，因为慢查询指的是逻辑处理过程慢，不包含等待等待时间。

所以开发的业务人员要注意过期时间，如果有大批量的key过期，要给过期时间设置一个随机范围，而不适宜全部在同一个时间过期，分散过期处理的压力。
```java
redis.expire_at(key, random.randint(86400) + expire_ts)
```
在一些活动中，因为活动是一期一回，下一期活动举办时候，前面几期的很多数据都可以丢弃了，所以需要给相关的活动数据设置一个过期时间，以减少不必要的Redis内存占用。如果不加注意，你可能会将过期时间设置为活动结束时间设置为活动结束时间，以减少不必要的Redis内存占用。
掌阅服务端在开发过程中就曾出现过多次因为大量 key 同时过期导致的卡顿报警现象，通过将过期时间随机化总是能很好地解决了这个问题，希望读者们今后能少犯这样的错误。
##### 虚拟内存页的置换策略
[了解操作系统中的页面置换算法](https://blog.csdn.net/sinat_36553913/article/details/76977599)

#### 惰性删除
但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。
- 获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。

#### 从库的过期策略
从库不会进行过期扫描，从库对过期的处理是被动的。主库在key到期时，会在AOF文件里面添加一条del指令，同步到所有从库，从库通过执行这条del指令来删除过期的key.

因为指令同步是异步进行的，所以主库过期的key的del指令没有即使同步到从库的话，会出现主从数据不一致，主库没有的数据在从库里还存在，比如上一节的集群环境分布式锁算法的漏洞就是因为这个同步延迟产生的。

## 持久化
Redis的数据全部存在内存里面，为了保证数据不丢失，就要去redis拥有持久化的机制。
Redis的持久化机制有两种，第一种是快照，第二种是AOF日志。快照是一次全量备份，AOF日志是连续的增量备份。快照是内存数据的二进制序列化，在存储上非常紧凑，而AOF日志记录的是内存数据修改的指令记录文本。AOF日志在长期的运行过程中会变得庞大无比，数据库重启的时候需要加载AOF日志进行指令重放，这个时间就会无比漫长。随意需要定期进行AOF重写，给AOF进行瘦身。
![avatar](https://user-gold-cdn.xitu.io/2018/7/10/164820eb27b6a97e?imageView2/0/w/1280/h/960/ignore-error/1)
### 快照原理
我们知道redis是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。
在服务线上请求的同时，Redis还需要进行内存快照，内存快照要求Reids必须进行文件IO操作，可文件IO是不能使用多路复用API.
这意味着单线程同时在服务线上的请求还要进行文件IO操作，文件IO操作会严重拖垮服务器请求的性能。**还有个重要问题就是为了不阻塞线上的业务，就需要边持久化边响应客户端请求**。持久化的同时，内存数据的结构还在改变，比如一个大型的hash字典正在持久化，结果一个请求过来把它给删掉了，还没有处理完，这些问题需要如何处理？
Redis使用操作系统的多进程COW(copy on write)机制来实现快照持久化，这个机制很有意思，也很少人知道。多进程COW也是检验一个程序员知识广度的重要指标。
#### fork(多进程)
redis在持久化的时候会调用glibc的函数fork产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端的请求。子进程刚刚产生时，它和父进程共享内存里面的代码和数据段。这时你可以将父子进程想象成一个连体婴儿，共享身体。这时linux操作系统的机制，为了节约内存资源，所以尽可能让他们共享起来。在进程分离的一瞬间，内存的增长几乎没有明显的变化。
子进程做数据持久化，它不会修改现在的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写在磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存数据结构进行不间断的修改。
这个时候就会使用操作系统的COW机制来进行数据段页面的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面进行数据修改的时候，会将被共享的页面复制分离出来一份，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。
![avatar](https://user-gold-cdn.xitu.io/2018/5/18/163711de3e2b6cb8?imageView2/0/w/1280/h/960/ignore-error/1)
随着父进程修改操作的持续进程，越来越多的共享页面被分离出来了，内存就会持续增长。但是也不会超过原有数据内存的两大小。另外一个Redis实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都被分离，被分离的往往只有其中一部分页面。每个页面的大小只有4K，一个Redis实例里面一般会有成千上万的页面。
子进程因为看到的数据没有变化，他能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么redis的持久化叫做快照的原因。接下来子进程就可以非常安心的遍历数据了进行持久化写磁盘的操作。

### AOF原理
AOF日志存储的是Redis服务器的顺序指令序列，AOF日志只记录对内存进行修改的指令记录。
假设AOF日志记录了自Redis实例创建以来所有的修改指令序列，那么就可以对一个空的Redis实例顺序执行所有的指令，也就是重放，来回复Reids当前实例的内存数据结构状态。
Redis会在收到客户端修改指令后，进行参数校验进行逻辑处理后，如果没有问题，就立刻将该指令文本存储到AOF日志中，也就是先执行指令才将日志存盘。这点不同于leveldb\hbase等存储引擎，他们都是先存储日志在做逻辑处理。
Redis在长期运行的过程中，AOF的日志会变得越来越长。如果实例宕机重启，重访整个AOF日志会非常耗时，导致长时间Redis无法对外提供服务。所以需要对AOF进行瘦身。
#### AOF重写
Redis提供了bgrewriteof指令用于对AOF日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列Redis的指令操作，序列化到一个新的AOF日志文件中。序列化完成后再将操作期间增量的AOF日志追加到这个新的AOF日志文件中，追加完成后就立刻代替旧的AOF日志文件了，瘦身工作就完成了。
#### fsync
AOF 日志是以文件的形式存在的，当程序对 AOF 日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘的。
这就意味着如果机器突然宕机，AOF 日志内容可能还没有来得及完全刷到磁盘中，这个时候就会出现日志丢失。那该怎么办？
Linux 的glibc提供了fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷到磁盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失。但是 fsync 是一个磁盘 IO 操作，它很慢！如果 Redis 执行一条指令就要 fsync 一次，那么 Redis 高性能的地位就不保了。
所以在生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作，周期 1s 是可以配置的。这是在数据安全性和性能之间做了一个折中，在保持高性能的同时，尽可能使得数据少丢失。
Redis 同样也提供了另外两种策略，一个是永不 fsync——让操作系统来决定何时同步磁盘，很不安全，另一个是来一个指令就 fsync 一次——非常慢。但是在生产环境基本不会使用，了解一下即可。
### 运维
快照是通过开启子进程的方式进行的，它是一个比较耗资源的操作。
- 遍历整个内存，大块写磁盘会加重系统负载
- AOF 的 fsync 是一个耗时的 IO 操作，它会降低 Redis 性能，同时也会增加系统 IO 负担
所以通常 Redis 的主节点是不会进行持久化操作，持久化操作主要在从节点进行。从节点是备份节点，没有来自客户端请求的压力，它的操作系统资源往往比较充沛。
但是如果出现网络分区，从节点长期连不上主节点，就会出现数据不一致的问题，特别是在网络分区出现的情况下又不小心主节点宕机了，那么数据就会丢失，所以在生产环境要做好实时监控工作，保证网络畅通或者能快速修复。另外还应该再增加一个从节点以降低网络分区的概率，只要有一个从节点数据同步正常，数据也就不会轻易丢失。
### Redis 4.0 混合持久化
重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。
Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。
![avatar](https://user-gold-cdn.xitu.io/2018/7/10/164821272ae19ebb?imageView2/0/w/1280/h/960/ignore-error/1)
于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。


